{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=9mXoGxAn6pM\n",
    "\n",
    "https://github.com/dreji18/NER-Training-Spacy-3.0/blob/main/NER%20Training%20with%20Spacy%20v3%20Notebook.ipynb\n",
    "\n",
    "https://datacorner.fr/spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/killian/.local/share/virtualenvs/back-P-6HUKwv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, separator, scale, destination=\"DESTINATION\", depart=\"DEPART\", error=\"ERROR\"):\n",
    "    csv = pd.read_csv(path, sep=separator, on_bad_lines='skip')\n",
    "    # randomize csv\n",
    "    csv = csv.sample(frac=1).reset_index(drop=True)\n",
    "    # print(csv)\n",
    "    dataset = []\n",
    "    datasetTest = []\n",
    "    index = 0\n",
    "    # convert scale to integer to stop filling train dataset\n",
    "    scale = int(len(csv) * scale)\n",
    "\n",
    "\n",
    "    for text in csv.TEXT:\n",
    "        entities = {'entities': []}\n",
    "        if text.find(csv[depart][index]) != -1:\n",
    "            if csv[error][index] == False:\n",
    "                positionDestination = text.find(csv[destination][index]), text.find(csv[destination][index]) + len(csv[destination][index]), \"DESTINATION\"\n",
    "                entities['entities'].append(positionDestination)\n",
    "                positionDepart = text.find(csv[depart][index]), text.find(csv[depart][index]) + len(csv[depart][index]), \"DEPART\"\n",
    "                entities['entities'].append(positionDepart)\n",
    "        cell = text, entities\n",
    "        if(index<scale):\n",
    "            # (\"texte\" , {\"entities\": [(0, 5, \"DESTINATION\"), (6, 11, \"DEPART\")]})\n",
    "            dataset.append(cell)\n",
    "        else:\n",
    "            datasetTest.append(cell)\n",
    "        index += 1\n",
    "    return dataset, datasetTest\n",
    "\n",
    "def add_ner_to_nlp(train_data):\n",
    "    # creation pipe vide\n",
    "    nlp = spacy.blank('fr')\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        # ajout du pipe ner seulement\n",
    "        nlp.add_pipe('ner')\n",
    "        \n",
    "    for text, annotations in train_data:\n",
    "        for startIndex, endIndex, label in annotations.get('entities', []):\n",
    "            ner.add_label(label)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to new spacy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 467/467 [00:00<00:00, 3806.86it/s]\n",
      "100%|██████████| 1868/1868 [00:00<00:00, 6731.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "db = DocBin()\n",
    "dataset, datasetTest = create_dataset(\"../asset/SpeechDestination.csv\", \",\", 0.2)\n",
    "\n",
    "for text, annot in tqdm(dataset): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./train.spacy\")\n",
    "\n",
    "db = DocBin()\n",
    "for text, annot in tqdm(datasetTest): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./test.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train du modèle :\n",
    "\n",
    "Récupérer le fichier de configuration spacy :\n",
    "\n",
    "https://spacy.io/usage/training#config\n",
    "\n",
    "Et aller dans son répertoire taper cette commande :\n",
    "\n",
    "python3 -m spacy init fill-config base_config.cfg config.cfg\n",
    "\n",
    "Lancer la config de train :\n",
    "\n",
    "python3 -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Tester le modèle : \n",
    "\n",
    "python3 -m spacy evaluate output/model-best/ train.spacy\n",
    "\n",
    "ents_p, ents_r, ents_f are the precision, recall and fscore for the NER task.\n",
    "tags_acc is the POS tagging accuracy.\n",
    "token_acc seems to be the precision for token segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate results : 1757\n",
      "Error results : 111\n",
      "Total results : 1868\n",
      "Accuracy : 0.9405781584582441\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(r\"./output/model-best\")\n",
    "score = {'Accurate':0, 'Error':0, 'Total':0}\n",
    "for text, annotations in datasetTest:\n",
    "    doc = nlp(text)\n",
    "    # get the word based on annotation index\n",
    "    try:\n",
    "        destination = text[annotations.get('entities', [])[0][0]:annotations.get('entities', [])[0][1]]\n",
    "        depart = text[annotations.get('entities', [])[1][0]:annotations.get('entities', [])[1][1]]\n",
    "        result = [(depart, 'DEPART'), (destination, 'DESTINATION')]\n",
    "        # get ent.text where ent.label_ == 'DEPART'\n",
    "        departPrediction = [ent.text for ent in doc.ents if ent.label_ == 'DEPART']\n",
    "        # get ent.text where ent.label_ == 'DESTINATION'\n",
    "        destinationPrediction = [ent.text for ent in doc.ents if ent.label_ == 'DESTINATION']\n",
    "\n",
    "        # Evaluate the Model\n",
    "        if(len(departPrediction) == 1 and len(destinationPrediction) == 1):\n",
    "            if(departPrediction[0] == depart and destinationPrediction[0] == destination):\n",
    "                score['Accurate'] += 1\n",
    "            else:\n",
    "                score['Error'] += 1\n",
    "        else:\n",
    "            score['Error'] += 1\n",
    "        score['Total'] += 1\n",
    "    except:\n",
    "        score['Error'] += 1\n",
    "        score['Total'] += 1\n",
    "\n",
    "    # spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "print('Accurate results : ' + str(score['Accurate']))\n",
    "print('Error results : ' + str(score['Error']))\n",
    "print('Total results : ' + str(score['Total']))\n",
    "print('Accuracy : ' + str(score['Accurate']/score['Total']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Quel train dois-je prendre si je veux aller à \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Montpellier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DESTINATION</span>\n",
       "</mark>\n",
       " en partant de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Toulouse\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEPART</span>\n",
       "</mark>\n",
       "?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Il fait combien dehors Alexis?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Je voudrais partir pour \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DESTINATION</span>\n",
       "</mark>\n",
       " en partant de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lille\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEPART</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Quel train dois-je prendre si je veux aller à Montpellier en partant de Toulouse?\") # input sample text\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter\n",
    "doc = nlp(\"Il fait combien dehors Alexis?\") # input sample text\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter\n",
    "doc = nlp(\"Je voudrais partir pour Paris en partant de Lille\") # input sample text\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "back-P-6HUKwv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4c47255976128ec6dc18c5a6c6a38d19b3ecbc446285b5c4242f45c1511372b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
